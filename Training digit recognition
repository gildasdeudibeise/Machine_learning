import tensorflow as tf
import matplotlib.pyplot as plt
import numpy as np
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
tf.keras.backend.set_floatx('float64')
from tensorflow.keras import backend as K
# Print tensorflow version
print(tf.__version__)
# Fix Mac-connected problems
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'
# Another way to fix Mac-connected problems
# conda install nomkl
np.random.seed(1)
tf.random.set_seed(1)


mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255., x_test / 255



plt.figure(1, figsize=(20, 10))
for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(x_train[i,:,:], cmap=plt.cm.gray_r)
    plt.title('Training[' + str(i) + ']: digit ' + str(y_train[i]))


idx_train = np.array(range(x_train.shape[0]))[(y_train == 0) | (y_train == 1)][:200]
print(idx_train.shape)
idx_test = np.array(range(len(x_test)))[(y_test == 0) | (y_test == 1)][:2000]
print(idx_test.shape)



x1_train = x_train[idx_train,:,:]
y1_train = y_train[idx_train]
print(y1_train)
x1_test = x_test[idx_test,:,:]
y1_test = y_test[idx_test]




x1_train_flat = x1_train.reshape(x1_train.shape[0], 28 * 28)
print(x1_train_flat.shape)
x1_test_flat = x1_test.reshape(x1_test.shape[0], 28 * 28)
print(x1_test_flat.shape)



nn1 = tf.keras.models.Sequential([
    tf.keras.layers.InputLayer(input_shape=(784,)),
    tf.keras.layers.Dense(10, activation='sigmoid'),
    tf.keras.layers.Dense(10, activation='sigmoid'),
    tf.keras.layers.Dense(1, activation='sigmoid'),
])



nn1.compile(optimizer='adam', loss=tf.keras.losses.MSE, metrics=['accuracy'])

nn1.fit(x1_train_flat, y1_train, epochs=15)


forecast1 = nn1(x1_test_flat).numpy()
print((forecast1[:,0] > 0.5).astype(int).shape)
print(y1_test.shape)
print('Accuracy of NN on test data 1: ' + str(np.mean((forecast1[:,0] > 0.5).astype(int) == y1_test)))


np.random.seed(1)
tf.random.set_seed(1)


idx_train = np.array(range(x_train.shape[0]))[(y_train == 4) | (y_train == 9)][:200]
print(idx_train.shape)
idx_test = np.array(range(len(x_test)))[(y_test == 4) | (y_test == 9)][:2000]
print(idx_test.shape)
x2_train = x_train[idx_train,:,:]
y2_train = y_train[idx_train]
print(y2_train)
x2_test = x_test[idx_test,:,:]
y2_test = y_test[idx_test]


class CatCrossE49(tf.keras.losses.Loss):
    def call(self, y_true, y_pred):
        y_pred = tf.convert_to_tensor(y_pred)
        y_true = tf.cast(y_true, y_pred.dtype)
        y_true_resc = (y_true - 4) / 5
        return K.mean(tf.square(y_pred - y_true_resc), axis=-1)
msl2 = CatCrossE49()



nn2 = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(10, activation='sigmoid'),
    tf.keras.layers.Dense(10, activation='sigmoid'),
    tf.keras.layers.Dense(2, activation='sigmoid')
])


nn2.compile(optimizer='adam', 
            loss=msl2,
            metrics=['accuracy'])
nn2.fit(x2_train, y2_train, epochs=100)



forecast2 = nn2(x2_test).numpy()
print(((forecast2[:,1] > forecast2[:,0]) * 5 + 4).shape)
print(y2_test.shape)
print('Accuracy of NN on test data 2: ' + str(np.mean(((forecast2[:,1] > forecast2[:,0]) * 5 + 4) == y2_test)))




lda1 = LinearDiscriminantAnalysis()
lda1.fit(x1_train_flat, y1_train)
forecast3 = lda1.predict(x1_test_flat)
print(forecast3.shape)
print(y1_test.shape)
print('Accuracy of LDA on test data 1: ' + str(np.mean(forecast3 == y1_test)))



lda2 = LinearDiscriminantAnalysis()
lda2.fit(x2_train.reshape(x2_train.shape[0], 28 * 28), y2_train)
forecast4 = lda2.predict(x2_test.reshape(x2_test.shape[0], 28 * 28))
print(forecast4.shape)
print(y2_test.shape)
print('Accuracy of LDA on test data 2: ' + str(np.mean(forecast4 == y2_test)))



np.random.seed(1)
tf.random.set_seed(1)


x3_train = x_train[:1000,:,:].reshape(1000,28,28,1)
print(x3_train.shape)
y3_train = y_train[:1000]
print(y3_train)
plt.imshow(x3_train[10,:,:,0], cmap=plt.cm.gray_r)



nn3 = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(4, (5, 5), activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(12, (5, 5), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10)
])
nn3.summary()


nn3.compile(optimizer='adam',
            loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
            metrics=['accuracy'])


nn3.fit(x3_train, y3_train, epochs=10)


forecast5 = nn3(x_test.reshape(x_test.shape[0],28,28,1)).numpy()
print(np.argmax(forecast5, 1).shape)
print(y_test.shape)
print('Accuracy of NN on full test data: ' + str(np.mean(np.argmax(forecast5, 1) == y_test)))
